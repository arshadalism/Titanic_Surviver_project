{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-17T06:34:56.160621200Z",
     "start_time": "2025-08-17T06:34:56.009488900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n5            6         0       3   \n6            7         0       1   \n7            8         0       3   \n8            9         1       3   \n9           10         1       2   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n5                                   Moran, Mr. James    male   NaN      0   \n6                            McCarthy, Mr. Timothy J    male  54.0      0   \n7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  \n5      0            330877   8.4583   NaN        Q  \n6      0             17463  51.8625   E46        S  \n7      1            349909  21.0750   NaN        S  \n8      2            347742  11.1333   NaN        S  \n9      0            237736  30.0708   NaN        C  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Moran, Mr. James</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>330877</td>\n      <td>8.4583</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>0</td>\n      <td>1</td>\n      <td>McCarthy, Mr. Timothy J</td>\n      <td>male</td>\n      <td>54.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>17463</td>\n      <td>51.8625</td>\n      <td>E46</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Palsson, Master. Gosta Leonard</td>\n      <td>male</td>\n      <td>2.0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>349909</td>\n      <td>21.0750</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n      <td>female</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>347742</td>\n      <td>11.1333</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>1</td>\n      <td>2</td>\n      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n      <td>female</td>\n      <td>14.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>237736</td>\n      <td>30.0708</td>\n      <td>NaN</td>\n      <td>C</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "train.head(10)\n",
    "# train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Embarked  \n0      0         A/5 21171   7.2500        S  \n1      0          PC 17599  71.2833        C  \n2      0  STON/O2. 3101282   7.9250        S  \n3      0            113803  53.1000        S  \n4      0            373450   8.0500        S  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data cleaning\n",
    "# Age -> Fill with median age\n",
    "# Embarked -> Fill with most common port\n",
    "# Cabin -> Drop(too many missing)\n",
    "\n",
    "train['Age'] = train['Age'].fillna(train['Age'].median())\n",
    "\n",
    "most_common_port = train['Embarked'].value_counts()\n",
    "train['Embarked'] = train['Embarked'].fillna(int(most_common_port.iloc[0]))\n",
    "# train.drop('Cabin', axis=1, inplace=True)\n",
    "\n",
    "train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-17T06:41:13.061286900Z",
     "start_time": "2025-08-17T06:41:13.051241400Z"
    }
   },
   "id": "e0025cb1af6dc614"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# Encode\n",
    "train = pd.get_dummies(train, columns=['Sex', 'Embarked'], drop_first=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-17T06:41:42.554983900Z",
     "start_time": "2025-08-17T06:41:42.539264900Z"
    }
   },
   "id": "472de122ca70b941"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "train['FamilySize'] = train['SibSp'] + train['Parch'] + 1\n",
    "train['IsAlone'] = (train['FamilySize'] == 1).astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-17T06:41:44.604178100Z",
     "start_time": "2025-08-17T06:41:44.600274300Z"
    }
   },
   "id": "108d6fb2bf717fab"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = train.drop(['Survived', 'PassengerId', 'Name', 'Ticket'], axis=1)\n",
    "y = train['Survived']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-17T06:41:46.818735100Z",
     "start_time": "2025-08-17T06:41:46.787846400Z"
    }
   },
   "id": "daf7b53403017e44"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 79.3296089385475\n",
      "Random Forest Accuracy: 82.12290502793296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AI_ML\\Pandas\\pythonProject1\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Logistic Regression\n",
    "logreg = LogisticRegression(max_iter=100)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_val)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_val, y_pred) * 100)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_val)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_val, y_pred_rf) * 100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-17T06:42:33.012127100Z",
     "start_time": "2025-08-17T06:42:32.871097200Z"
    }
   },
   "id": "547cf45e0b925aa1"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[91 14]\n",
      " [18 56]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85       105\n",
      "           1       0.80      0.76      0.78        74\n",
      "\n",
      "    accuracy                           0.82       179\n",
      "   macro avg       0.82      0.81      0.81       179\n",
      "weighted avg       0.82      0.82      0.82       179\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_val, y_pred_rf))\n",
    "print(classification_report(y_val, y_pred_rf))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-17T06:42:37.114950100Z",
     "start_time": "2025-08-17T06:42:37.094515100Z"
    }
   },
   "id": "6c58b0c3a4c89852"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Pclass                                          Name   Age  \\\n",
      "0          892       3                              Kelly, Mr. James  None   \n",
      "1          893       3              Wilkes, Mrs. James (Ellen Needs)  None   \n",
      "2          894       2                     Myles, Mr. Thomas Francis  None   \n",
      "3          895       3                              Wirz, Mr. Albert  None   \n",
      "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  None   \n",
      "5          897       3                    Svensson, Mr. Johan Cervin  None   \n",
      "6          898       3                          Connolly, Miss. Kate  None   \n",
      "7          899       2                  Caldwell, Mr. Albert Francis  None   \n",
      "8          900       3     Abrahim, Mrs. Joseph (Sophie Halaut Easu)  None   \n",
      "9          901       3                       Davies, Mr. John Samuel  None   \n",
      "\n",
      "   SibSp  Parch     Ticket  Fare Cabin  Sex_male  Embarked_Q  Embarked_S  \\\n",
      "0      0      0     330911  None   NaN      True        True       False   \n",
      "1      1      0     363272  None   NaN     False       False        True   \n",
      "2      0      0     240276  None   NaN      True        True       False   \n",
      "3      0      0     315154  None   NaN      True       False        True   \n",
      "4      1      1    3101298  None   NaN     False       False        True   \n",
      "5      0      0       7538  None   NaN      True       False        True   \n",
      "6      0      0     330972  None   NaN     False        True       False   \n",
      "7      1      1     248738  None   NaN      True       False        True   \n",
      "8      0      0       2657  None   NaN     False       False       False   \n",
      "9      2      0  A/4 48871  None   NaN      True       False        True   \n",
      "\n",
      "   FamilySize  IsAlone  \n",
      "0           1        1  \n",
      "1           2        0  \n",
      "2           1        1  \n",
      "3           1        1  \n",
      "4           3        0  \n",
      "5           1        1  \n",
      "6           1        1  \n",
      "7           3        0  \n",
      "8           1        1  \n",
      "9           3        0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_7948\\3239884210.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test['Age'] = test[\"Age\"].fillna(train[\"Age\"].median(), inplace=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_7948\\3239884210.py:2: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test['Age'] = test[\"Age\"].fillna(train[\"Age\"].median(), inplace=True)\n",
      "D:\\AI_ML\\Pandas\\pythonProject1\\.venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_7948\\3239884210.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test['Fare'] = test[\"Fare\"].fillna(test[\"Fare\"].median(), inplace=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_7948\\3239884210.py:3: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test['Fare'] = test[\"Fare\"].fillna(test[\"Fare\"].median(), inplace=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- Embarked_C\n",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[40]\u001B[39m\u001B[32m, line 10\u001B[39m\n\u001B[32m      6\u001B[39m test[\u001B[33m\"\u001B[39m\u001B[33mIsAlone\u001B[39m\u001B[33m\"\u001B[39m] = (test[\u001B[33m\"\u001B[39m\u001B[33mFamilySize\u001B[39m\u001B[33m\"\u001B[39m] == \u001B[32m1\u001B[39m).astype(\u001B[38;5;28mint\u001B[39m)\n\u001B[32m      8\u001B[39m \u001B[38;5;66;03m# X_test = test.drop([\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"], axis=1, errors=\"ignore\")\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m predictions = \u001B[43mrf\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     12\u001B[39m submission = pd.DataFrame({\u001B[33m\"\u001B[39m\u001B[33mPassengerId\u001B[39m\u001B[33m\"\u001B[39m: test[\u001B[33m\"\u001B[39m\u001B[33mPassengerId\u001B[39m\u001B[33m\"\u001B[39m], \u001B[33m\"\u001B[39m\u001B[33mSurvived\u001B[39m\u001B[33m\"\u001B[39m: predictions})\n\u001B[32m     13\u001B[39m submission.to_csv(\u001B[33m\"\u001B[39m\u001B[33msubmission1.csv\u001B[39m\u001B[33m\"\u001B[39m, index=\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AI_ML\\Pandas\\pythonProject1\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:903\u001B[39m, in \u001B[36mForestClassifier.predict\u001B[39m\u001B[34m(self, X)\u001B[39m\n\u001B[32m    882\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[32m    883\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    884\u001B[39m \u001B[33;03m    Predict class for X.\u001B[39;00m\n\u001B[32m    885\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    901\u001B[39m \u001B[33;03m        The predicted classes.\u001B[39;00m\n\u001B[32m    902\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m903\u001B[39m     proba = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpredict_proba\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    905\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.n_outputs_ == \u001B[32m1\u001B[39m:\n\u001B[32m    906\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.classes_.take(np.argmax(proba, axis=\u001B[32m1\u001B[39m), axis=\u001B[32m0\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AI_ML\\Pandas\\pythonProject1\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:945\u001B[39m, in \u001B[36mForestClassifier.predict_proba\u001B[39m\u001B[34m(self, X)\u001B[39m\n\u001B[32m    943\u001B[39m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[32m    944\u001B[39m \u001B[38;5;66;03m# Check data\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m945\u001B[39m X = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_validate_X_predict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    947\u001B[39m \u001B[38;5;66;03m# Assign chunk of trees to jobs\u001B[39;00m\n\u001B[32m    948\u001B[39m n_jobs, _, _ = _partition_estimators(\u001B[38;5;28mself\u001B[39m.n_estimators, \u001B[38;5;28mself\u001B[39m.n_jobs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AI_ML\\Pandas\\pythonProject1\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:637\u001B[39m, in \u001B[36mBaseForest._validate_X_predict\u001B[39m\u001B[34m(self, X)\u001B[39m\n\u001B[32m    634\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    635\u001B[39m     ensure_all_finite = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m637\u001B[39m X = \u001B[43mvalidate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    638\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    639\u001B[39m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    640\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mDTYPE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    641\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcsr\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    642\u001B[39m \u001B[43m    \u001B[49m\u001B[43mreset\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    643\u001B[39m \u001B[43m    \u001B[49m\u001B[43mensure_all_finite\u001B[49m\u001B[43m=\u001B[49m\u001B[43mensure_all_finite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    644\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    645\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m issparse(X) \u001B[38;5;129;01mand\u001B[39;00m (X.indices.dtype != np.intc \u001B[38;5;129;01mor\u001B[39;00m X.indptr.dtype != np.intc):\n\u001B[32m    646\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mNo support for np.int64 index based sparse matrices\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AI_ML\\Pandas\\pythonProject1\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2929\u001B[39m, in \u001B[36mvalidate_data\u001B[39m\u001B[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001B[39m\n\u001B[32m   2845\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mvalidate_data\u001B[39m(\n\u001B[32m   2846\u001B[39m     _estimator,\n\u001B[32m   2847\u001B[39m     /,\n\u001B[32m   (...)\u001B[39m\u001B[32m   2853\u001B[39m     **check_params,\n\u001B[32m   2854\u001B[39m ):\n\u001B[32m   2855\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Validate input data and set or check feature names and counts of the input.\u001B[39;00m\n\u001B[32m   2856\u001B[39m \n\u001B[32m   2857\u001B[39m \u001B[33;03m    This helper function should be used in an estimator that requires input\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m   2927\u001B[39m \u001B[33;03m        validated.\u001B[39;00m\n\u001B[32m   2928\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m2929\u001B[39m     \u001B[43m_check_feature_names\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_estimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2930\u001B[39m     tags = get_tags(_estimator)\n\u001B[32m   2931\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m tags.target_tags.required:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AI_ML\\Pandas\\pythonProject1\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2787\u001B[39m, in \u001B[36m_check_feature_names\u001B[39m\u001B[34m(estimator, X, reset)\u001B[39m\n\u001B[32m   2784\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m missing_names \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m unexpected_names:\n\u001B[32m   2785\u001B[39m     message += \u001B[33m\"\u001B[39m\u001B[33mFeature names must be in the same order as they were in fit.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m2787\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(message)\n",
      "\u001B[31mValueError\u001B[39m: The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- Embarked_C\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-17T06:45:57.869138200Z",
     "start_time": "2025-08-17T06:45:57.770672300Z"
    }
   },
   "id": "4577bebf852c8a10"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
